import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Seed for reproducibility
np.random.seed(1)
import tensorflow as tf
tf.random.set_seed(1)

# Load dataset
df = pd.read_csv('fiftystocks.csv')  # Assume columns are 'Stock1', 'Stock2', ..., 'Stock50'
print(df.isna().sum())  # Check for missing values
df.dropna(inplace=True)  # Remove rows with NaNs

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df)

# Function to create a dataset for LSTM
def create_dataset(data, look_back=1, forecast_horizon=10):
    X, Y = [], []
    for i in range(len(data) - look_back - forecast_horizon + 1):
        a = data[i:(i + look_back), :]
        X.append(a)
        Y.append(data[i + look_back:i + look_back + forecast_horizon, :])
    return np.array(X), np.array(Y)

# Prepare the data
look_back = 60
forecast_horizon = 10
X, Y = create_dataset(scaled_data, look_back, forecast_horizon)

# Split data into train and test sets
train_size = int(len(X) * 0.72)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

# Build the LSTM model
model = Sequential([
    LSTM(100, return_sequences=True, input_shape=(look_back, df.shape[1])),
    LSTM(100),
    Dropout(0.3),
    Dense(df.shape[1] * forecast_horizon)
])

# Compile and train the model
optimizer = Adam(learning_rate=0.001, clipvalue=1.0)  # Gradient clipping
model.compile(optimizer=optimizer, loss='mean_squared_error')

early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)
model.fit(X_train, Y_train, epochs=5, batch_size=128, verbose=1, callbacks=[early_stopping])

# Making predictions
test_predict = model.predict(X_test)

# Check for NaNs in predictions
if np.isnan(test_predict).any():
    print("NaNs detected in predictions")
else:
    test_predict = test_predict.reshape(test_predict.shape[0], forecast_horizon, df.shape[1])
    test_predict = scaler.inverse_transform(test_predict.reshape(-1, df.shape[1])).reshape(test_predict.shape)

    # Compute returns for each horizon and plot results
    portfolios = {}
    for horizon in range(forecast_horizon):
        predicted_prices = test_predict[:, horizon, :]
        last_prices = df.values[train_size + look_back + horizon - 1:-forecast_horizon + horizon]
        predicted_returns = (predicted_prices - last_prices) / last_prices
        top_indices = np.argsort(-predicted_returns.mean(axis=0))[:4]
        portfolios[f'P{horizon+1}'] = df.columns[top_indices].tolist()
        average_returns = predicted_returns.mean(axis=0)[top_indices]

        fig, ax = plt.subplots(figsize=(10, 5))
        for i in top_indices:
            ax.plot(predicted_prices[:, i], label=f'Predicted {df.columns[i]}')
            ax.plot(last_prices[:, i], label=f'Actual {df.columns[i]}', alpha=0.7)
        ax.set_title(f'Time Horizon {horizon+1}%: Portfolio {portfolios[f"P{horizon+1}"]}\nReturns: {average_returns}')
        ax.legend()
        plt.show()

    # Print portfolio returns
    for key, value in portfolios.items():
        print(f"{key}: {value}")
